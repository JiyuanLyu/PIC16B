{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:PIC16B] *",
      "language": "python",
      "name": "conda-env-PIC16B-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhilChodrow/PIC16B/blob/master/lectures/tf/tf-5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "compound-switch"
      },
      "source": [
        "# Text Generation with Recurrent Neural Networks\n",
        "\n",
        "In this set of lecture notes, we'll consider a new kind of machine learning task. Previously, we've focused on *classification* problems. In classification problems, the goal is to assign a given piece of data to one of several categories. Today, we'll instead consider a simple  *generation* problem. A *generative* model can be used to create \"realistic\" examples after it's been trained. Generative models are at the heart of machine learning topics like deepfakes, language modeling, and [style transfer](https://www.tensorflow.org/tutorials/generative/style_transfer).  \n",
        "\n",
        "\n",
        "\n",
        "*Parts of these lecture notes were based on [this tutorial](https://keras.io/examples/generative/lstm_character_level_text_generation/). It is recommended to run the code contained in these notes in a Google Colab instance with GPU acceleration enabled.* "
      ],
      "id": "compound-switch"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "august-syracuse"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd"
      ],
      "id": "august-syracuse",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VO91nEUSzWtO"
      },
      "source": [
        "\n",
        "## Our Task\n",
        "\n",
        "Today, we are going to see whether we can teach an algorithm to understand and reproduce the pinnacle of cultural achievement; the benchmark against which all art is to be judged; the mirror that reveals to humany its truest self. I speak, of course, about *Star Trek: Deep Space Nine.*\n",
        "\n",
        "<figure class=\"image\" style=\"width:100px\">\n",
        "  <img src=\"https://raw.githubusercontent.com/PhilChodrow/PIC16B/master/_images/DS9.jpg\" alt=\"\">\n",
        "  <figcaption><i></i></figcaption>\n",
        "</figure>\n",
        "\n",
        "In particular, we are going to attempt to teach a neural  network to generate *episode scripts*. This a text generation task: after training, our hope is that our model will be able to create scripts that are reasonably realistic in their appearance. \n"
      ],
      "id": "VO91nEUSzWtO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOJ-RVVNp4M0"
      },
      "source": [
        "start_episode = 20 # Start in Season 2, Season 1 is not very good\n",
        "num_episodes = 50  # only pick this many episodes to train on\n",
        "\n",
        "url = \"https://github.com/PhilChodrow/PIC16B/blob/master/datasets/star_trek_scripts.json?raw=true\"\n",
        "star_trek_scripts = pd.read_json(url)\n",
        "\n",
        "cleaned = star_trek_scripts[\"DS9\"].str.replace(\"\\n\\n\\n\\n\\n\\nThe Deep Space Nine Transcripts -\", \"\")\n",
        "cleaned = cleaned.str.split(\"\\n\\n\\n\\n\\n\\n\\n\").str.get(-2)\n",
        "text = \"\\n\\n\".join(cleaned[start_episode:(start_episode + num_episodes)])\n",
        "for char in ['\\xa0', 'à', 'é', \"}\", \"{\"]:\n",
        "    text = text.replace(char, \"\")"
      ],
      "id": "jOJ-RVVNp4M0",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdzuQ2AoqP63",
        "outputId": "e774beb9-d39d-437b-bc03-2dd4746ec720"
      },
      "source": [
        "print(text[0:500])"
      ],
      "id": "sdzuQ2AoqP63",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Last\n",
            "time on Deep Space Nine.  \n",
            "SISKO: This is the emblem of the Alliance for Global Unity. They call\n",
            "themselves the Circle. \n",
            "O'BRIEN: What gives them the right to mess up our station? \n",
            "ODO: They're an extremist faction who believe in Bajor for the\n",
            "Bajorans. \n",
            "SISKO: I can't loan you a Starfleet runabout without knowing where you\n",
            "plan on taking it. \n",
            "KIRA: To Cardassia Four to rescue a Bajoran prisoner of war. \n",
            "(The prisoners are rescued.) \n",
            "KIRA: Come on. We have a ship waiting. \n",
            "JARO: What you \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icYyItL_1Qc3"
      },
      "source": [
        "Our first step, as usual, is data preparation. What we need to do is format the data in such a way that we can treat the situation as a classification problem after all. That is: \n",
        "\n",
        "> Given a string of text, predict the next character in that string. \n",
        "\n",
        "Doing this repeatedly will allow the model to generate large bodies of text. \n",
        "\n",
        "To do this, we want to split our data like so: \n",
        "\n",
        "```\n",
        "predictor = \"to boldly g\"\n",
        "target    = \"o\"\n",
        "```\n",
        "\n",
        "The following function will do this for us. The `max_len` argument gives the number of characters that should be in the predictor string, and the `step_size` argument lets us skip indices if we want to in order to decrease the size of the data. "
      ],
      "id": "icYyItL_1Qc3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abroad-hypothesis"
      },
      "source": [
        "def split(raw_text, max_len, step_size = 1):\n",
        "\n",
        "    lines = []\n",
        "    next_chars = []\n",
        "\n",
        "    for i in range(0, len(text) - max_len, step_size):\n",
        "        lines.append(text[i:i+max_len])\n",
        "        next_chars.append(text[i+max_len])\n",
        "    \n",
        "    return lines, next_chars"
      ],
      "id": "abroad-hypothesis",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "distributed-performance",
        "outputId": "32c1bc11-dab0-4c63-e47a-9c0c684d685d"
      },
      "source": [
        "max_len = 20\n",
        "\n",
        "lines, next_chars =  split(text, max_len = max_len, step_size = 5)\n",
        "for i in range(10, 15):\n",
        "    print(lines[i] + \"     =>    \" + next_chars[i])"
      ],
      "id": "distributed-performance",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "he emblem of the All     =>    i\n",
            "blem of the Alliance     =>     \n",
            "of the Alliance for      =>    G\n",
            "e Alliance for Globa     =>    l\n",
            "iance for Global Uni     =>    t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojwSL8eX2F2p"
      },
      "source": [
        "Our next step is to vectorize the characters. This is similar to the word vectorization task, but it's simple enough in this case that's arguably more convenient to actually handle it outside of TensorFlow. It is also possible to handle vectorization using TensorFlow tools, as demonstrated in [this tutorial](https://www.tensorflow.org/tutorials/text/text_generation). "
      ],
      "id": "ojwSL8eX2F2p"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSaFo1c88XQS"
      },
      "source": [
        "chars = sorted(set(text))\n",
        "char_indices = {char : chars.index(char) for char in chars}\n",
        "X = np.zeros((len(lines), max_len, len(chars)))\n",
        "y = np.zeros((len(lines), 1), dtype = np.int32)\n",
        "for i, line in enumerate(lines):\n",
        "\tfor t, char in enumerate(line):\n",
        "\t\tX[i, t, char_indices[char]] = 1\n",
        "\ty[i] = char_indices[next_chars[i]]"
      ],
      "id": "gSaFo1c88XQS",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0fmER3H-KSn"
      },
      "source": [
        "Let's take a look at what happened here: "
      ],
      "id": "O0fmER3H-KSn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MJqyOgI4cjr",
        "outputId": "5b8d7ef4-2933-4133-c034-7a77d4287bb2"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "id": "-MJqyOgI4cjr",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((314163, 20, 78), (314163, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5vN0_A3-M8y",
        "outputId": "5e87b81b-e48e-4256-f40b-7ed67f9720f2"
      },
      "source": [
        "X[0]"
      ],
      "id": "a5vN0_A3-M8y",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OgFmGrG-UkM",
        "outputId": "559711b6-535c-49a3-b821-720f94e8a536"
      },
      "source": [
        "y[0]"
      ],
      "id": "1OgFmGrG-UkM",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([42], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6fgVac-4fze"
      },
      "source": [
        "Now we're ready to perform a train-test split: "
      ],
      "id": "E6fgVac-4fze"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jppzOG0uV_6i"
      },
      "source": [
        "train_len = int(0.7*X.shape[0])\n",
        "X_train = X[0:train_len]\n",
        "X_val = X[train_len:]\n",
        "\n",
        "y_train = y[0:train_len]\n",
        "y_val  = y[train_len:]"
      ],
      "id": "jppzOG0uV_6i",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjLMfcZE4jgX"
      },
      "source": [
        "Model time! We'll use a simple *Long Short-Term Memory* (LSTM) model for this example. LSTMs are one example of *recurrent* neural network layers. Here's a diagram illustrating the schematic functioning of a recurrent layer. \n",
        "\n",
        "![](https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png)\n",
        "*Image credit: [Chris Olah](https://colah.github.io/posts/2015-08-Understanding-LSTMs/), OpenAI*\n",
        "\n",
        "On the lefthand side, we have a \"zoomed out\" picture of a recurrent neural network layer. On the righthand side, we see the \"zoomed in\" version. The key point here is that output $h_2$ depends not only on input $x_2$, but also, indirectly, on inputs $x_0$ and $x_1$. This means that recurrent neural networks are highly suitable for modeling processes that have temporal structure. Text is an example: the last few characters are the \"history\" of the text. Timeseries data are another clear example, and indeed, we can use a very similar workflow to the one we'll use today in order to do forecasting in timeseries. \n",
        "\n",
        "Since training for this kind of task gets expensive fast, we'll use just one LSTM layer followed by a `Dense` output layer. "
      ],
      "id": "YjLMfcZE4jgX"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alive-debut"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    layers.LSTM(128, name = \"LSTM\", input_shape=(max_len, len(chars))),\n",
        "    layers.Dense(len(chars), activation = \"softmax\")        \n",
        "])"
      ],
      "id": "alive-debut",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un1ValtI9W0R"
      },
      "source": [
        "model.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
        "              optimizer = \"adam\")"
      ],
      "id": "Un1ValtI9W0R",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_CdRi-L461U"
      },
      "source": [
        "Time for training. We'll do just one epoch for now, mostly just to prove that we've set up our model correctly. "
      ],
      "id": "t_CdRi-L461U"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLzlxzGw9iI5",
        "outputId": "20e10b3d-31f3-4119-9229-34d1b5fbe009"
      },
      "source": [
        "# code I used to train and save the model\n",
        "model.fit(X_train, \n",
        "          y_train,\n",
        "          validation_data= (X_val, y_val),\n",
        "          batch_size=128, epochs = 200)\n",
        "model.save('DS9_model') \n",
        "\n",
        "# model.fit(X_train, \n",
        "#           y_train,\n",
        "#           validation_data= (X_val, y_val),\n",
        "#           batch_size=128, epochs = 20)"
      ],
      "id": "JLzlxzGw9iI5",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 2.6118 - val_loss: 2.2148\n",
            "Epoch 2/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 2.1149 - val_loss: 2.0331\n",
            "Epoch 3/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.9624 - val_loss: 1.9149\n",
            "Epoch 4/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.8634 - val_loss: 1.8569\n",
            "Epoch 5/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.7910 - val_loss: 1.7955\n",
            "Epoch 6/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.7330 - val_loss: 1.7631\n",
            "Epoch 7/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.6833 - val_loss: 1.7207\n",
            "Epoch 8/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.6411 - val_loss: 1.6959\n",
            "Epoch 9/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.6051 - val_loss: 1.6711\n",
            "Epoch 10/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.5729 - val_loss: 1.6507\n",
            "Epoch 11/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.5447 - val_loss: 1.6398\n",
            "Epoch 12/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.5194 - val_loss: 1.6197\n",
            "Epoch 13/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.4959 - val_loss: 1.6103\n",
            "Epoch 14/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.4747 - val_loss: 1.5969\n",
            "Epoch 15/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.4554 - val_loss: 1.5940\n",
            "Epoch 16/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.4378 - val_loss: 1.5876\n",
            "Epoch 17/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.4204 - val_loss: 1.5778\n",
            "Epoch 18/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.4043 - val_loss: 1.5728\n",
            "Epoch 19/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3902 - val_loss: 1.5655\n",
            "Epoch 20/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3764 - val_loss: 1.5658\n",
            "Epoch 21/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3626 - val_loss: 1.5672\n",
            "Epoch 22/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3504 - val_loss: 1.5590\n",
            "Epoch 23/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3372 - val_loss: 1.5652\n",
            "Epoch 24/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3254 - val_loss: 1.5622\n",
            "Epoch 25/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3141 - val_loss: 1.5585\n",
            "Epoch 26/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.3035 - val_loss: 1.5567\n",
            "Epoch 27/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2923 - val_loss: 1.5623\n",
            "Epoch 28/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2829 - val_loss: 1.5645\n",
            "Epoch 29/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2725 - val_loss: 1.5654\n",
            "Epoch 30/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2622 - val_loss: 1.5675\n",
            "Epoch 31/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2531 - val_loss: 1.5701\n",
            "Epoch 32/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2437 - val_loss: 1.5823\n",
            "Epoch 33/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2352 - val_loss: 1.5868\n",
            "Epoch 34/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2259 - val_loss: 1.5888\n",
            "Epoch 35/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2176 - val_loss: 1.6002\n",
            "Epoch 36/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2092 - val_loss: 1.5957\n",
            "Epoch 37/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.2012 - val_loss: 1.6034\n",
            "Epoch 38/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1922 - val_loss: 1.6058\n",
            "Epoch 39/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1845 - val_loss: 1.6234\n",
            "Epoch 40/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1768 - val_loss: 1.6241\n",
            "Epoch 41/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1699 - val_loss: 1.6331\n",
            "Epoch 42/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1624 - val_loss: 1.6337\n",
            "Epoch 43/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1562 - val_loss: 1.6452\n",
            "Epoch 44/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1492 - val_loss: 1.6521\n",
            "Epoch 45/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1418 - val_loss: 1.6592\n",
            "Epoch 46/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1363 - val_loss: 1.6662\n",
            "Epoch 47/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1300 - val_loss: 1.6799\n",
            "Epoch 48/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1246 - val_loss: 1.6752\n",
            "Epoch 49/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1176 - val_loss: 1.6907\n",
            "Epoch 50/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1126 - val_loss: 1.6875\n",
            "Epoch 51/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1070 - val_loss: 1.6946\n",
            "Epoch 52/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.1016 - val_loss: 1.7058\n",
            "Epoch 53/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0961 - val_loss: 1.7033\n",
            "Epoch 54/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0906 - val_loss: 1.7139\n",
            "Epoch 55/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0879 - val_loss: 1.7237\n",
            "Epoch 56/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0811 - val_loss: 1.7333\n",
            "Epoch 57/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0778 - val_loss: 1.7309\n",
            "Epoch 58/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0729 - val_loss: 1.7467\n",
            "Epoch 59/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0680 - val_loss: 1.7544\n",
            "Epoch 60/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0646 - val_loss: 1.7599\n",
            "Epoch 61/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0598 - val_loss: 1.7561\n",
            "Epoch 62/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0562 - val_loss: 1.7676\n",
            "Epoch 63/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0521 - val_loss: 1.7696\n",
            "Epoch 64/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0484 - val_loss: 1.7872\n",
            "Epoch 65/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0458 - val_loss: 1.7810\n",
            "Epoch 66/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0418 - val_loss: 1.7989\n",
            "Epoch 67/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0399 - val_loss: 1.7957\n",
            "Epoch 68/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0367 - val_loss: 1.7998\n",
            "Epoch 69/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0322 - val_loss: 1.8089\n",
            "Epoch 70/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0287 - val_loss: 1.8187\n",
            "Epoch 71/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0268 - val_loss: 1.8199\n",
            "Epoch 72/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0274 - val_loss: 1.8174\n",
            "Epoch 73/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0210 - val_loss: 1.8280\n",
            "Epoch 74/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0193 - val_loss: 1.8364\n",
            "Epoch 75/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0167 - val_loss: 1.8354\n",
            "Epoch 76/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0142 - val_loss: 1.8429\n",
            "Epoch 77/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0121 - val_loss: 1.8468\n",
            "Epoch 78/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0084 - val_loss: 1.8531\n",
            "Epoch 79/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0060 - val_loss: 1.8550\n",
            "Epoch 80/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0045 - val_loss: 1.8557\n",
            "Epoch 81/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0010 - val_loss: 1.8723\n",
            "Epoch 82/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 1.0001 - val_loss: 1.8696\n",
            "Epoch 83/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9977 - val_loss: 1.8810\n",
            "Epoch 84/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9944 - val_loss: 1.8758\n",
            "Epoch 85/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9934 - val_loss: 1.9018\n",
            "Epoch 86/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9922 - val_loss: 1.8763\n",
            "Epoch 87/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9886 - val_loss: 1.8862\n",
            "Epoch 88/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9872 - val_loss: 1.8883\n",
            "Epoch 89/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9850 - val_loss: 1.9009\n",
            "Epoch 90/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9845 - val_loss: 1.9005\n",
            "Epoch 91/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9823 - val_loss: 1.9044\n",
            "Epoch 92/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9800 - val_loss: 1.9130\n",
            "Epoch 93/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9799 - val_loss: 1.9156\n",
            "Epoch 94/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9772 - val_loss: 1.9201\n",
            "Epoch 95/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9762 - val_loss: 1.9161\n",
            "Epoch 96/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9745 - val_loss: 1.9215\n",
            "Epoch 97/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9757 - val_loss: 1.9337\n",
            "Epoch 98/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9718 - val_loss: 1.9391\n",
            "Epoch 99/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9699 - val_loss: 1.9337\n",
            "Epoch 100/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9685 - val_loss: 1.9308\n",
            "Epoch 101/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9658 - val_loss: 1.9512\n",
            "Epoch 102/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9661 - val_loss: 1.9466\n",
            "Epoch 103/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9649 - val_loss: 1.9508\n",
            "Epoch 104/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9648 - val_loss: 1.9488\n",
            "Epoch 105/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9637 - val_loss: 1.9454\n",
            "Epoch 106/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9609 - val_loss: 1.9578\n",
            "Epoch 107/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9600 - val_loss: 1.9544\n",
            "Epoch 108/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9581 - val_loss: 1.9598\n",
            "Epoch 109/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9578 - val_loss: 1.9710\n",
            "Epoch 110/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9567 - val_loss: 1.9709\n",
            "Epoch 111/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9568 - val_loss: 1.9642\n",
            "Epoch 112/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9535 - val_loss: 1.9681\n",
            "Epoch 113/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9548 - val_loss: 1.9854\n",
            "Epoch 114/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9515 - val_loss: 1.9781\n",
            "Epoch 115/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9520 - val_loss: 1.9792\n",
            "Epoch 116/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9496 - val_loss: 1.9877\n",
            "Epoch 117/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9491 - val_loss: 1.9812\n",
            "Epoch 118/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9484 - val_loss: 1.9896\n",
            "Epoch 119/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9464 - val_loss: 1.9876\n",
            "Epoch 120/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9450 - val_loss: 1.9998\n",
            "Epoch 121/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9467 - val_loss: 1.9850\n",
            "Epoch 122/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9437 - val_loss: 2.0028\n",
            "Epoch 123/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9448 - val_loss: 1.9967\n",
            "Epoch 124/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9459 - val_loss: 1.9972\n",
            "Epoch 125/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9407 - val_loss: 2.0025\n",
            "Epoch 126/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9419 - val_loss: 2.0150\n",
            "Epoch 127/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9409 - val_loss: 2.0088\n",
            "Epoch 128/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9386 - val_loss: 2.0081\n",
            "Epoch 129/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9371 - val_loss: 2.0262\n",
            "Epoch 130/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9393 - val_loss: 2.0169\n",
            "Epoch 131/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9366 - val_loss: 2.0154\n",
            "Epoch 132/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9376 - val_loss: 2.0185\n",
            "Epoch 133/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9379 - val_loss: 2.0253\n",
            "Epoch 134/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9353 - val_loss: 2.0164\n",
            "Epoch 135/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9365 - val_loss: 2.0275\n",
            "Epoch 136/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9321 - val_loss: 2.0231\n",
            "Epoch 137/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9339 - val_loss: 2.0235\n",
            "Epoch 138/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9312 - val_loss: 2.0243\n",
            "Epoch 139/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9310 - val_loss: 2.0320\n",
            "Epoch 140/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9289 - val_loss: 2.0366\n",
            "Epoch 141/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9313 - val_loss: 2.0419\n",
            "Epoch 142/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9293 - val_loss: 2.0299\n",
            "Epoch 143/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9292 - val_loss: 2.0355\n",
            "Epoch 144/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9284 - val_loss: 2.0453\n",
            "Epoch 145/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9304 - val_loss: 2.0407\n",
            "Epoch 146/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9287 - val_loss: 2.0380\n",
            "Epoch 147/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9267 - val_loss: 2.0525\n",
            "Epoch 148/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9252 - val_loss: 2.0471\n",
            "Epoch 149/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9236 - val_loss: 2.0339\n",
            "Epoch 150/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9252 - val_loss: 2.0492\n",
            "Epoch 151/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9239 - val_loss: 2.0445\n",
            "Epoch 152/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9243 - val_loss: 2.0537\n",
            "Epoch 153/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9245 - val_loss: 2.0511\n",
            "Epoch 154/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9227 - val_loss: 2.0581\n",
            "Epoch 155/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9223 - val_loss: 2.0595\n",
            "Epoch 156/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9218 - val_loss: 2.0571\n",
            "Epoch 157/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9203 - val_loss: 2.0458\n",
            "Epoch 158/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9198 - val_loss: 2.0579\n",
            "Epoch 159/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9187 - val_loss: 2.0570\n",
            "Epoch 160/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9186 - val_loss: 2.0492\n",
            "Epoch 161/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9189 - val_loss: 2.0475\n",
            "Epoch 162/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9186 - val_loss: 2.0594\n",
            "Epoch 163/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9175 - val_loss: 2.0681\n",
            "Epoch 164/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9158 - val_loss: 2.0719\n",
            "Epoch 165/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9157 - val_loss: 2.0765\n",
            "Epoch 166/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9139 - val_loss: 2.0709\n",
            "Epoch 167/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9138 - val_loss: 2.0710\n",
            "Epoch 168/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9150 - val_loss: 2.0690\n",
            "Epoch 169/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9136 - val_loss: 2.0694\n",
            "Epoch 170/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9138 - val_loss: 2.0821\n",
            "Epoch 171/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9156 - val_loss: 2.0810\n",
            "Epoch 172/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9123 - val_loss: 2.0885\n",
            "Epoch 173/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9132 - val_loss: 2.0799\n",
            "Epoch 174/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9130 - val_loss: 2.0706\n",
            "Epoch 175/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9105 - val_loss: 2.0948\n",
            "Epoch 176/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9103 - val_loss: 2.0812\n",
            "Epoch 177/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9133 - val_loss: 2.0888\n",
            "Epoch 178/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9106 - val_loss: 2.0921\n",
            "Epoch 179/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9115 - val_loss: 2.0869\n",
            "Epoch 180/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9079 - val_loss: 2.0839\n",
            "Epoch 181/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9091 - val_loss: 2.0820\n",
            "Epoch 182/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9095 - val_loss: 2.0876\n",
            "Epoch 183/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9069 - val_loss: 2.0806\n",
            "Epoch 184/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9069 - val_loss: 2.0864\n",
            "Epoch 185/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9084 - val_loss: 2.0875\n",
            "Epoch 186/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9096 - val_loss: 2.0967\n",
            "Epoch 187/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9082 - val_loss: 2.0814\n",
            "Epoch 188/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9051 - val_loss: 2.0872\n",
            "Epoch 189/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9069 - val_loss: 2.0957\n",
            "Epoch 190/200\n",
            "1719/1719 [==============================] - 9s 6ms/step - loss: 0.9070 - val_loss: 2.0915\n",
            "Epoch 191/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9053 - val_loss: 2.1104\n",
            "Epoch 192/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9054 - val_loss: 2.0967\n",
            "Epoch 193/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9041 - val_loss: 2.0991\n",
            "Epoch 194/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9067 - val_loss: 2.0934\n",
            "Epoch 195/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9061 - val_loss: 2.1057\n",
            "Epoch 196/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9029 - val_loss: 2.1014\n",
            "Epoch 197/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9068 - val_loss: 2.1174\n",
            "Epoch 198/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9028 - val_loss: 2.1104\n",
            "Epoch 199/200\n",
            "1719/1719 [==============================] - 10s 6ms/step - loss: 0.9082 - val_loss: 2.0973\n",
            "Epoch 200/200\n",
            "1719/1719 [==============================] - 9s 5ms/step - loss: 0.9009 - val_loss: 2.1031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: DS9_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: DS9_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro1uhnsC5G1r"
      },
      "source": [
        "Now, instead of training the entire model live during lecture, I'm instead going to load in a saved model that I previously trained for 200 epochs on Google Colab. On Colab, each epoch takes around 10s or so. 200 epochs corresponds to roughly 30 minutes. "
      ],
      "id": "Ro1uhnsC5G1r"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IYE6EhM5ZIq"
      },
      "source": [
        "model = tf.keras.models.load_model('DS9_model')"
      ],
      "id": "0IYE6EhM5ZIq",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kD7rl_Se5qru"
      },
      "source": [
        "Generative models define *probability distributions* over the space of possible outputs. So, our overall algorithm is going to generate new text in a partially randomized way. To make this happen, we define a `sample` function which will take the model outputs, turn them into probabilities, and then sample from the probabilities to produce a single character (well, technically, an integer corresponding to a single character). \n",
        "\n",
        "An important parameter here is the so-called *temperature* (this terminology comes from statistical physics. When the temperature is high, the model will more frequently choose low-probability characters. This is sometimes interpreted as \"creativity,\" and leads to more unpredictable outputs. When the temperature is low, on the other hand, the model will \"play it safe\" and tend to stick to known patterns. In the extreme limiting case as the temperature approaches 0, the model will ultimately get stuck in \"loops\" in which it repeats common phrases over and over again. "
      ],
      "id": "kD7rl_Se5qru"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bronze-battle"
      },
      "source": [
        "def sample(preds, temp):\n",
        "    preds = np.asarray(preds).astype(\"float64\")\n",
        "    probs = np.exp(preds/temp)\n",
        "    probs = probs / probs.sum()\n",
        "    samp = np.random.multinomial(1, probs, 1)\n",
        "    return np.argmax(samp)"
      ],
      "id": "bronze-battle",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5Gix5AK6b8i"
      },
      "source": [
        "Now that we know how to sample from the model predictions to create a new character, let's now define a convenient function that will allow us to create entire strings of specified length using this process. "
      ],
      "id": "E5Gix5AK6b8i"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvjDjrjvADEf"
      },
      "source": [
        "def generate_string(seed_index, temp, gen_length, model): \n",
        "\n",
        "    gen_seq = np.zeros((max_len + gen_length, len(chars)))\n",
        "    seed = X[seed_index]\n",
        "    gen_seq[0:max_len] = seed\n",
        "    \n",
        "    gen_text = lines[seed_index]\n",
        "\n",
        "    for i in range(0, gen_length):\n",
        "        window = gen_seq[i: i + max_len]\n",
        "        preds = model.predict(np.array([window]))[0]\n",
        "        next_index = sample(preds, temp)\n",
        "        gen_seq[max_len + i, next_index] = True\n",
        "\n",
        "        next_char = chars[next_index]\n",
        "        gen_text += next_char\n",
        "\n",
        "    return(gen_text)"
      ],
      "id": "BvjDjrjvADEf",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLJ30Flj67PN"
      },
      "source": [
        "Let's try it out! "
      ],
      "id": "fLJ30Flj67PN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCepapOYAmIf",
        "outputId": "05bbd9e6-2986-4cad-d13f-2480303fb549"
      },
      "source": [
        "gen_length = 500\n",
        "seed_index = 10000\n",
        "\n",
        "for temp in [0.01, 0.02, 0.03, 0.04, 0.05]:\n",
        "\n",
        "    gen = generate_string(seed_index, temp, gen_length, model)\n",
        "\n",
        "    print(4*\"-\")\n",
        "    print(\"TEMPERATURE: \" + str(temp))\n",
        "    print(gen[:-gen_length], end=\"\")\n",
        "    print(\" => \", end = \"\")\n",
        "    print(gen[-gen_length:], \"\")"
      ],
      "id": "vCepapOYAmIf",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----\n",
            "TEMPERATURE: 0.01\n",
            "tioning. \n",
            "KIRA: No p => reficies and not for the first time to be respect thing? \n",
            "O'BRIEN: Yes, I don't you are no inside of the Federation. \n",
            "KIRA [OC]: Now gives there. \n",
            "DAX: It wanted to talk down the wormhole. \n",
            "DAX: I do be a missed the station want to do their programme was at the saying isnevering their componeeration and for the death. The right in the put me too. \n",
            "QUARK: Well, you're all the patting to have any of your facerion. \n",
            "KIRA: I was all minutes again. \n",
            "ODO: I stouth it is the first family too of look. \n",
            " \n",
            "----\n",
            "TEMPERATURE: 0.02\n",
            "tioning. \n",
            "KIRA: No p => refitian systems who asked to like a trictle the oll find of a way I guess weapons. \n",
            "O'BRIEN: Yes, I was see. He's a do ranaboly was again. \n",
            "ROM: No. Now, you wouldn't realise you was an a homanal offecture. \n",
            "KIRA: No, it could take reaching around to think the oursers him out of the sent has been coming matiat on the same trans of the shot to Bajor. \n",
            "KIRA: I'm sorry, I don't know what you're tellod have my eary from the station. \n",
            "KIRA: Of course you would saying is take a looks out tood come of \n",
            "----\n",
            "TEMPERATURE: 0.03\n",
            "tioning. \n",
            "KIRA: No p => reficies and not here. \n",
            "ODO: Oh, are you are you ask the decind betakes. \n",
            "KIRA: I'm not sure that the Klina monk's every things we couldn't belusi\n",
            "and I'm the old to the Cardassian sixte it the matiation. \n",
            "DAX: I'm not sure that I'm afrages. \n",
            "BASHIR: ]\n",
            "\n",
            "KUG: I'll sall a groating toder. To you, I wouldn't you again atteating up. \n",
            "O'BRIEN: I don't said you? \n",
            "KOLITU: What do you all the Federation. \n",
            "KIRA [OC]: Now gives there. \n",
            "KIRA: Braney find out they? \n",
            "KIRA: Before your thousalted by my ships's \n",
            "----\n",
            "TEMPERATURE: 0.04\n",
            "tioning. \n",
            "KIRA: No p => reficies and checceed that with the Gamma Leye. \n",
            "ODO: Well, you could think I'm sure they xeleagragions. \n",
            "KIRA: Oh, and there beherion. \n",
            "BASHIR: Where you say the symbiont reshaps 0ine Xecondstands about your ? Enter. \n",
            "KIRA: king then you was sure that dayst family's convince. It's a sQuaddet the station the Vellage in onf terpiget of the station. \n",
            "PEL: The man's notes You're all the station. \n",
            "SISKO: What if you do we have a Nigral spice in a Xethen is /lear no : Are. \n",
            "ODO: I can ser our sale to \n",
            "----\n",
            "TEMPERATURE: 0.05\n",
            "tioning. \n",
            "KIRA: No p => reficies and do with you Comes. \n",
            "mUnerrloth here it eisher prefessoly have never : wasn't she was Yerearnted by the Order. It won't werend then carefRing friend. \n",
            "ODO: There's nothing to ask the restraction 5o she day are. \n",
            "ODO: I stoulds a re1tlement. : Ven'DaLait!0, you asked to meet of the knowh he's a back to the ship as I was just beco7t to Lieuten. \n",
            "ODO: Kir, orem that Maias and the game agrsa3pled faultion. The seaty is a ship can grappous. \n",
            "74ALZS: Bries on Erie? Tell me, what I was stan \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzsYhZro71_x"
      },
      "source": [
        "Let's make a few observations. \n",
        "\n",
        "1. First of all, it can take a surprisingly long time to make predictions using our model. This is because we have to call the `predict()` method *for each character*, in order to ensure that the model appropriately takes into account its recent predictions. This can take a pretty long time! \n",
        "2. Second, determining a good value for the temperature can take some experimentation. Note that low temperatures don't necessarily correspond to \"more realistic\" text -- they just correspond to highlighting common patterns in the text, possibly in excess. Higher temperatures also don't necessarily correspond to a \"creative\" algorithm in any normal sense of the word -- set the temperature too high, and you'll just get gibberish. \n",
        "\n",
        "## Specialization\n",
        "\n",
        "In this case, we were able to create a model for generating Star Trek scripts using an instance of Google Colab in roughly 15 minutes. This model is highly limited. Although it clearly has learned some relevant features of Star Trek scripts, there's no way that you'd mistake the output of the model for an actual script by a screenwriter. Considering how hard this was, imagine how much effort and computational resources are required to create more general language models! Indeed, as highlighted in a [recent and controversial paper](https://faculty.washington.edu/ebender/papers/Stochastic_Parrots.pdf), training large language models in this day and age can require energy expenditure comparable to a trans-Atlantic flight! "
      ],
      "id": "vzsYhZro71_x"
    }
  ]
}