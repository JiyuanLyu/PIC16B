{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning again again\n",
    "\n",
    "*This worksheet was originally designed by [Erin George](https://www.math.ucla.edu/~egeo/) (Department of Mathematics, UCLA). It has been subsequently revised by later TAs and instructors.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will be doing... machine learning.  Specifically, we'll be doing a model similar to the one you just saw in lecture, where the features are a mix of two different types.  We'll actually be using the same types as in lecture: text and scalars.  However, it will be a lot more complicated because we'll have a lot of different text features.\n",
    "\n",
    "Our dataset will be the [TMDB 5000 Movie Dataset from Kaggle](https://www.kaggle.com/tmdb/tmdb-movie-metadata?select=tmdb_5000_movies.csv).  As always, I've put it on CCLE.  Our ultimate goal for this dataset is to predcit the score of the movie from other features.  But first, let's take a look at the dataset!  (We'll only be checking the top row of the dataframe since each row takes up quite a bit of vertical space.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...</td>\n",
       "      <td>http://www.avatarmovie.com/</td>\n",
       "      <td>19995</td>\n",
       "      <td>[{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...</td>\n",
       "      <td>en</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>[{\"name\": \"Ingenious Film Partners\", \"id\": 289...</td>\n",
       "      <td>[{\"iso_3166_1\": \"US\", \"name\": \"United States o...</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>[{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget                                             genres  \\\n",
       "0  237000000  [{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"nam...   \n",
       "\n",
       "                      homepage     id  \\\n",
       "0  http://www.avatarmovie.com/  19995   \n",
       "\n",
       "                                            keywords original_language  \\\n",
       "0  [{\"id\": 1463, \"name\": \"culture clash\"}, {\"id\":...                en   \n",
       "\n",
       "  original_title                                           overview  \\\n",
       "0         Avatar  In the 22nd century, a paraplegic Marine is di...   \n",
       "\n",
       "   popularity                               production_companies  \\\n",
       "0  150.437577  [{\"name\": \"Ingenious Film Partners\", \"id\": 289...   \n",
       "\n",
       "                                production_countries release_date     revenue  \\\n",
       "0  [{\"iso_3166_1\": \"US\", \"name\": \"United States o...   2009-12-10  2787965087   \n",
       "\n",
       "   runtime                                   spoken_languages    status  \\\n",
       "0    162.0  [{\"iso_639_1\": \"en\", \"name\": \"English\"}, {\"iso...  Released   \n",
       "\n",
       "                       tagline   title  vote_average  vote_count  \n",
       "0  Enter the World of Pandora.  Avatar           7.2       11800  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('tmdb_5000_movies.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of features here!  As always, some of are pretty useless.  Let's remove those.  We all will remove the \"original_language\" feature because it's hard to work with, even though it might be useful.\n",
    "\n",
    "Some of the features are stored in, of all things, a list of Python dictionaries? (actually, a string of a list of Python dictionaries!)  These represent features that can have multiple different values!  The dictionary bit is a little extraneous, but it just provides different ways of looking at the values.  Let's unpack the dictionaries to make the features a string containing the simplest representation of all the values.  Then we can deal with these features using normal text processing layers.\n",
    "\n",
    "Also, might as well drop NaNs now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>237000000</td>\n",
       "      <td>28 12 14 878</td>\n",
       "      <td>1463 2964 3386 3388 3679 3801 9685 9840 9882 9...</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>289 306 444 574</td>\n",
       "      <td>US GB</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>2787965087</td>\n",
       "      <td>162.0</td>\n",
       "      <td>en es</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      budget        genres                                           keywords  \\\n",
       "0  237000000  28 12 14 878  1463 2964 3386 3388 3679 3801 9685 9840 9882 9...   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "\n",
       "  production_companies production_countries release_date     revenue  runtime  \\\n",
       "0      289 306 444 574                US GB   2009-12-10  2787965087    162.0   \n",
       "\n",
       "  spoken_languages    status                      tagline  vote_average  \n",
       "0            en es  Released  Enter the World of Pandora.           7.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3959, 14)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['homepage', 'id', 'original_title', 'title', 'vote_count', 'original_language'], inplace=True)\n",
    "df['genres'] = df['genres'].apply(lambda x : ' '.join([str(y['id']) for y in eval(x)]))\n",
    "df['keywords'] = df['keywords'].apply(lambda x : ' '.join([str(y['id']) for y in eval(x)]))\n",
    "df['production_companies'] = df['production_companies'].apply(lambda x : ' '.join([str(y['id']) for y in eval(x)]))\n",
    "df['production_countries'] = df['production_countries'].apply(lambda x : ' '.join([str(y['iso_3166_1']) for y in eval(x)]))\n",
    "df['spoken_languages'] = df['spoken_languages'].apply(lambda x : ' '.join([str(y['iso_639_1']) for y in eval(x)]))\n",
    "df.dropna(inplace=True)\n",
    "display(df.head(1))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous example, budget and revenue are going to likely be somewhat on a log scale.  Let's take the log of them.  The +1 is to fix the values that are zero (whose log would be -infinity) without changing the other values too much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log(budget)</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>log(revenue)</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>vote_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.283571</td>\n",
       "      <td>28 12 14 878</td>\n",
       "      <td>1463 2964 3386 3388 3679 3801 9685 9840 9882 9...</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>289 306 444 574</td>\n",
       "      <td>US GB</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>21.748578</td>\n",
       "      <td>162.0</td>\n",
       "      <td>en es</td>\n",
       "      <td>Released</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log(budget)        genres  \\\n",
       "0    19.283571  28 12 14 878   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  1463 2964 3386 3388 3679 3801 9685 9840 9882 9...   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "\n",
       "  production_companies production_countries release_date  log(revenue)  \\\n",
       "0      289 306 444 574                US GB   2009-12-10     21.748578   \n",
       "\n",
       "   runtime spoken_languages    status                      tagline  \\\n",
       "0    162.0            en es  Released  Enter the World of Pandora.   \n",
       "\n",
       "   vote_average  \n",
       "0           7.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['budget'] = np.log(df['budget'] + 1) #some are zero\n",
    "df['revenue'] = np.log(df['revenue'] + 1)\n",
    "df.rename(columns = {'budget': 'log(budget)', 'revenue':'log(revenue)'}, inplace=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do one hot encoding for `status`.  There are only three predefined values it could take, so it's safe to do this before splitting.  We can use Pandas `get_dummies` then because it's easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log(budget)</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>release_date</th>\n",
       "      <th>log(revenue)</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>tagline</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>Post Production</th>\n",
       "      <th>Released</th>\n",
       "      <th>Rumored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.283571</td>\n",
       "      <td>28 12 14 878</td>\n",
       "      <td>1463 2964 3386 3388 3679 3801 9685 9840 9882 9...</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>289 306 444 574</td>\n",
       "      <td>US GB</td>\n",
       "      <td>2009-12-10</td>\n",
       "      <td>21.748578</td>\n",
       "      <td>162.0</td>\n",
       "      <td>en es</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log(budget)        genres  \\\n",
       "0    19.283571  28 12 14 878   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  1463 2964 3386 3388 3679 3801 9685 9840 9882 9...   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "\n",
       "  production_companies production_countries release_date  log(revenue)  \\\n",
       "0      289 306 444 574                US GB   2009-12-10     21.748578   \n",
       "\n",
       "   runtime spoken_languages                      tagline  vote_average  \\\n",
       "0    162.0            en es  Enter the World of Pandora.           7.2   \n",
       "\n",
       "   Post Production  Released  Rumored  \n",
       "0                0         1        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.join(pd.get_dummies(df['status']))\n",
    "df.drop(columns=['status'], inplace=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The date feature is a little weird.  It'll probably be easier to work with month and year, so let's do that.  We can also adjust year so that it starts at the lowest year on the list, since only the relative difference matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log(budget)</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>log(revenue)</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>tagline</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>Post Production</th>\n",
       "      <th>Released</th>\n",
       "      <th>Rumored</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.283571</td>\n",
       "      <td>28 12 14 878</td>\n",
       "      <td>1463 2964 3386 3388 3679 3801 9685 9840 9882 9...</td>\n",
       "      <td>In the 22nd century, a paraplegic Marine is di...</td>\n",
       "      <td>150.437577</td>\n",
       "      <td>289 306 444 574</td>\n",
       "      <td>US GB</td>\n",
       "      <td>21.748578</td>\n",
       "      <td>162.0</td>\n",
       "      <td>en es</td>\n",
       "      <td>Enter the World of Pandora.</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   log(budget)        genres  \\\n",
       "0    19.283571  28 12 14 878   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  1463 2964 3386 3388 3679 3801 9685 9840 9882 9...   \n",
       "\n",
       "                                            overview  popularity  \\\n",
       "0  In the 22nd century, a paraplegic Marine is di...  150.437577   \n",
       "\n",
       "  production_companies production_countries  log(revenue)  runtime  \\\n",
       "0      289 306 444 574                US GB     21.748578    162.0   \n",
       "\n",
       "  spoken_languages                      tagline  vote_average  \\\n",
       "0            en es  Enter the World of Pandora.           7.2   \n",
       "\n",
       "   Post Production  Released  Rumored  Year  Month  \n",
       "0                0         1        0    93     12  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.join(df[['release_date']].apply(\n",
    "    axis=1, result_type='expand',\n",
    "    func=(lambda x : [int(x['release_date'][:4]), int(x['release_date'][5:7])])))\n",
    "df.drop(columns=['release_date'], inplace=True)\n",
    "df.rename(columns={0: 'Year', 1: 'Month'}, inplace=True)\n",
    "df['Year'] = df['Year'] - min(df['Year'])\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split!  Both to labels/features and trains/test/validation.  Also, our label `vote_average` takes values between 0 and 10.  For reasons that will be clearly later, it's nicer if it takes values between 0 and 1.  Let's change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log(budget)</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>overview</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_companies</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>log(revenue)</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>tagline</th>\n",
       "      <th>Post Production</th>\n",
       "      <th>Released</th>\n",
       "      <th>Rumored</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>16.118096</td>\n",
       "      <td>35 10749</td>\n",
       "      <td>596 2041 2580 157524</td>\n",
       "      <td>Stranded and alone on a desert island during a...</td>\n",
       "      <td>4.570043</td>\n",
       "      <td>3287 13419 57736</td>\n",
       "      <td>IT GB</td>\n",
       "      <td>13.302426</td>\n",
       "      <td>89.0</td>\n",
       "      <td>it el en</td>\n",
       "      <td>A snooty socialite is stranded on a Mediterran...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      log(budget)    genres              keywords  \\\n",
       "3097    16.118096  35 10749  596 2041 2580 157524   \n",
       "\n",
       "                                               overview  popularity  \\\n",
       "3097  Stranded and alone on a desert island during a...    4.570043   \n",
       "\n",
       "     production_companies production_countries  log(revenue)  runtime  \\\n",
       "3097     3287 13419 57736                IT GB     13.302426     89.0   \n",
       "\n",
       "     spoken_languages                                            tagline  \\\n",
       "3097         it el en  A snooty socialite is stranded on a Mediterran...   \n",
       "\n",
       "      Post Production  Released  Rumored  Year  Month  \n",
       "3097                0         1        0    86     10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2226, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = df.drop(columns = ['vote_average'])\n",
    "y = df['vote_average']/10\n",
    "\n",
    "x_trv, x_test, y_trv, y_test = train_test_split(x, y, random_state=209)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_trv, y_trv)\n",
    "\n",
    "display(x_train.head(1))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in lecture, we'll be using Tensorflow Datasets.  This is very similar to what we did before, except we need to split our features into more parts.  Each \"text\" column needs to be its own group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(x, y):\n",
    "    return tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            {\n",
    "                \"genres\": x['genres'],\n",
    "                \"keywords\": x['keywords'],\n",
    "                \"overview\": x['overview'],\n",
    "                \"production_companies\": x['production_companies'],\n",
    "                \"production_countries\": x['production_countries'],\n",
    "                \"spoken_languages\": x['spoken_languages'],\n",
    "                \"tagline\": x['tagline'],\n",
    "                \"scalars\": x[['log(budget)', 'popularity', 'log(revenue)',\n",
    "                              'runtime', 'Post Production', 'Released',\n",
    "                              'Rumored', 'Year', 'Month']]\n",
    "            },\n",
    "            {\n",
    "                'vote_average': y\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "train = make_data(x_train, y_train).batch(20)\n",
    "val = make_data(x_val, y_val).batch(20)\n",
    "test = make_data(x_test, y_test).batch(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the vectorization layer.  This is the same as before except we need to do it A LOT.  Let's create a function for it so we don't have to keep rewriting code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow import keras\n",
    "import re\n",
    "import string\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup\n",
    "\n",
    "size_vocabulary = 2000\n",
    "\n",
    "def standardization(input_data):\n",
    "    lowercase = tf.strings.lower(input_data)\n",
    "    no_punctuation = tf.strings.regex_replace(lowercase,\n",
    "                                  '[%s]' % re.escape(string.punctuation),'')\n",
    "    return no_punctuation \n",
    "\n",
    "def create_vectorize_layer(train, feature):\n",
    "    vectorize_layer = TextVectorization(\n",
    "        standardize=standardization,\n",
    "        max_tokens=size_vocabulary,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=500) \n",
    "\n",
    "    vectorize_layer.adapt(train.map(lambda x, y: x[feature]))\n",
    "    return vectorize_layer\n",
    "\n",
    "vectorize_genres    = create_vectorize_layer(train, 'genres')\n",
    "vectorize_keywords  = create_vectorize_layer(train, 'keywords')\n",
    "vectorize_overview  = create_vectorize_layer(train, 'overview')\n",
    "vectorize_companies = create_vectorize_layer(train, 'production_companies')\n",
    "vectorize_countries = create_vectorize_layer(train, 'production_countries')\n",
    "vectorize_languages = create_vectorize_layer(train, 'spoken_languages')\n",
    "vectorize_tagline   = create_vectorize_layer(train, 'tagline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same with the inputs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_string_input(name):\n",
    "    return keras.Input(\n",
    "        shape = (1,), \n",
    "        name = name,\n",
    "        dtype = \"string\"\n",
    "    )\n",
    "\n",
    "genres_input    = create_string_input('genres')\n",
    "keywords_input  = create_string_input('keywords')\n",
    "overview_input  = create_string_input('overview')\n",
    "companies_input = create_string_input('production_companies')\n",
    "countries_input = create_string_input('production_countries')\n",
    "languages_input = create_string_input('spoken_languages')\n",
    "tagline_input   = create_string_input('tagline')\n",
    "\n",
    "scalars_input = keras.Input(\n",
    "    shape = (9,), \n",
    "    name = \"scalars\",\n",
    "    dtype = \"float64\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually make the structure of our neural network.  This is the same for all the text features right now, but we might want to change them independently.  So here I did copy and paste it.  (Also, note the activation functions!  Those are important)\n",
    "\n",
    "At the end, we have one output node.  We'll be doing regression, so this is find.  We put a sigmoid activation function on this layer.  This forces all the output values to be between 0 and 1.  This means that the predicted scores will never be out of range, and it will be easier for our model to learn to predict scores! (Sneaky, right?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "genres (InputLayer)             [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keywords (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "overview (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "production_companies (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "production_countries (InputLaye [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "spoken_languages (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tagline (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization (TextVectori (None, 500)          0           genres[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization_1 (TextVecto (None, 500)          0           keywords[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization_2 (TextVecto (None, 500)          0           overview[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization_3 (TextVecto (None, 500)          0           production_companies[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization_4 (TextVecto (None, 500)          0           production_countries[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization_5 (TextVecto (None, 500)          0           spoken_languages[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "text_vectorization_6 (TextVecto (None, 500)          0           tagline[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_genres (Embedding)    (None, 500, 3)       6000        text_vectorization[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "embedding_keywords (Embedding)  (None, 500, 3)       6000        text_vectorization_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_overview (Embedding)  (None, 500, 3)       6000        text_vectorization_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_companies (Embedding) (None, 500, 3)       6000        text_vectorization_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_countries (Embedding) (None, 500, 3)       6000        text_vectorization_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_languages (Embedding) (None, 500, 3)       6000        text_vectorization_5[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_tagline (Embedding)   (None, 500, 3)       6000        text_vectorization_6[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 500, 3)       0           embedding_genres[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 3)       0           embedding_keywords[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 500, 3)       0           embedding_overview[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 500, 3)       0           embedding_companies[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 500, 3)       0           embedding_countries[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 500, 3)       0           embedding_languages[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 500, 3)       0           embedding_tagline[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 3)            0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 3)            0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 3)            0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 3)            0           dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 3)            0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 3)            0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 3)            0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 3)            0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 3)            0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 3)            0           global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 3)            0           global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 3)            0           global_average_pooling1d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 3)            0           global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 3)            0           global_average_pooling1d_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "scalars (InputLayer)            [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 32)           128         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           128         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           128         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           128         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           128         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           128         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           128         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32)           320         scalars[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           dense[0][0]                      \n",
      "                                                                 dense_1[0][0]                    \n",
      "                                                                 dense_2[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "                                                                 dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32)           8224        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "vote_average (Dense)            (None, 1)            33          dense_8[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 51,473\n",
      "Trainable params: 51,473\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "genres_features = vectorize_genres(genres_input)\n",
    "genres_features = layers.Embedding(size_vocabulary, 3, name = \"embedding_genres\")(genres_features)\n",
    "genres_features = layers.Dropout(0.2)(genres_features)\n",
    "genres_features = layers.GlobalAveragePooling1D()(genres_features)\n",
    "genres_features = layers.Dropout(0.2)(genres_features)\n",
    "genres_features = layers.Dense(32, activation='sigmoid')(genres_features)\n",
    "\n",
    "keywords_features = vectorize_keywords(keywords_input)\n",
    "keywords_features = layers.Embedding(size_vocabulary, 3, name = \"embedding_keywords\")(keywords_features)\n",
    "keywords_features = layers.Dropout(0.2)(keywords_features)\n",
    "keywords_features = layers.GlobalAveragePooling1D()(keywords_features)\n",
    "keywords_features = layers.Dropout(0.2)(keywords_features)\n",
    "keywords_features = layers.Dense(32, activation='sigmoid')(keywords_features)\n",
    "\n",
    "overview_features = vectorize_overview(overview_input)\n",
    "overview_features = layers.Embedding(size_vocabulary, 3, name = \"embedding_overview\")(overview_features)\n",
    "overview_features = layers.Dropout(0.2)(overview_features)\n",
    "overview_features = layers.GlobalAveragePooling1D()(overview_features)\n",
    "overview_features = layers.Dropout(0.2)(overview_features)\n",
    "overview_features = layers.Dense(32, activation='sigmoid')(overview_features)\n",
    "\n",
    "companies_features = vectorize_companies(companies_input)\n",
    "companies_features = layers.Embedding(size_vocabulary, 3, name = \"embedding_companies\")(companies_features)\n",
    "companies_features = layers.Dropout(0.2)(companies_features)\n",
    "companies_features = layers.GlobalAveragePooling1D()(companies_features)\n",
    "companies_features = layers.Dropout(0.2)(companies_features)\n",
    "companies_features = layers.Dense(32, activation='sigmoid')(companies_features)\n",
    "\n",
    "countries_features = vectorize_countries(countries_input)\n",
    "countries_features = layers.Embedding(size_vocabulary, 3, name = \"embedding_countries\")(countries_features)\n",
    "countries_features = layers.Dropout(0.2)(countries_features)\n",
    "countries_features = layers.GlobalAveragePooling1D()(countries_features)\n",
    "countries_features = layers.Dropout(0.2)(countries_features)\n",
    "countries_features = layers.Dense(32, activation='sigmoid')(countries_features)\n",
    "\n",
    "languages_features = vectorize_languages(languages_input)\n",
    "languages_features = layers.Embedding(size_vocabulary, 3, name = \"embedding_languages\")(languages_features)\n",
    "languages_features = layers.Dropout(0.2)(languages_features)\n",
    "languages_features = layers.GlobalAveragePooling1D()(languages_features)\n",
    "languages_features = layers.Dropout(0.2)(languages_features)\n",
    "languages_features = layers.Dense(32, activation='sigmoid')(languages_features)\n",
    "\n",
    "tagline_features = vectorize_tagline(tagline_input)\n",
    "tagline_features = layers.Embedding(size_vocabulary, 3, name = \"embedding_tagline\")(tagline_features)\n",
    "tagline_features = layers.Dropout(0.2)(tagline_features)\n",
    "tagline_features = layers.GlobalAveragePooling1D()(tagline_features)\n",
    "tagline_features = layers.Dropout(0.2)(tagline_features)\n",
    "tagline_features = layers.Dense(32, activation='sigmoid')(tagline_features)\n",
    "\n",
    "scalar_features = layers.Dense(32, activation='sigmoid')(scalars_input)\n",
    "\n",
    "main = layers.concatenate([genres_features, keywords_features, overview_features,\n",
    "                           companies_features, countries_features, languages_features,\n",
    "                           tagline_features, scalar_features], axis = 1)\n",
    "\n",
    "main = layers.Dense(32)(main)\n",
    "output = layers.Dense(1, name = \"vote_average\", activation='sigmoid')(main)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs = [genres_input, keywords_input, overview_input,\n",
    "              companies_input, countries_input, languages_input,\n",
    "              tagline_input, scalars_input],\n",
    "    outputs = output\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "112/112 [==============================] - 4s 12ms/step - loss: 0.0125 - val_loss: 0.0086\n",
      "Epoch 2/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0092 - val_loss: 0.0087\n",
      "Epoch 3/50\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0086\n",
      "Epoch 4/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0087 - val_loss: 0.0084\n",
      "Epoch 5/50\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 6/50\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 7/50\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 8/50\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0080\n",
      "Epoch 9/50\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0081\n",
      "Epoch 10/50\n",
      "112/112 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0082\n",
      "Epoch 11/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 12/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 13/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0084 - val_loss: 0.0084\n",
      "Epoch 14/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 15/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 16/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0083 - val_loss: 0.0097\n",
      "Epoch 17/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0083 - val_loss: 0.0104\n",
      "Epoch 18/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 19/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 20/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0081 - val_loss: 0.0102\n",
      "Epoch 21/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0080 - val_loss: 0.0094\n",
      "Epoch 22/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0089\n",
      "Epoch 23/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 24/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 25/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 26/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0079\n",
      "Epoch 27/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 28/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0075 - val_loss: 0.0078\n",
      "Epoch 29/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 30/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0074 - val_loss: 0.0077\n",
      "Epoch 31/50\n",
      "112/112 [==============================] - 1s 5ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 32/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 33/50\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 34/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 35/50\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 36/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 37/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 38/50\n",
      "112/112 [==============================] - 1s 7ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 39/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 40/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 41/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 43/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 44/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 45/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 46/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 47/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 48/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0070 - val_loss: 0.0079\n",
      "Epoch 49/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 50/50\n",
      "112/112 [==============================] - 1s 6ms/step - loss: 0.0069 - val_loss: 0.0078\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = \"adam\",\n",
    "              loss = 'mse'\n",
    ")\n",
    "history = model.fit(train, \n",
    "                    validation_data=val,\n",
    "                    epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly, we evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 2ms/step - loss: 0.0068\n",
      "38/38 [==============================] - 0s 2ms/step - loss: 0.0078\n",
      "Train MSE: 0.006774891167879105\n",
      "Train r^2: 0.33446840790368193\n",
      "Validation MSE: 0.007823353633284569\n",
      "Validation r^2: 0.25895581959762376\n"
     ]
    }
   ],
   "source": [
    "train_mse = model.evaluate(train)\n",
    "train_var = y_train.var()\n",
    "\n",
    "val_mse = model.evaluate(val)\n",
    "val_var = y_val.var()\n",
    "\n",
    "print(f'Train MSE: {train_mse}')\n",
    "print(f'Train r^2: {(train_var - train_mse)/train_var}')\n",
    "\n",
    "print(f'Validation MSE: {val_mse}')\n",
    "print(f'Validation r^2: {(val_var - val_mse)/val_var}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
