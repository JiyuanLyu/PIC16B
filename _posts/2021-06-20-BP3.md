---
layout: post
title:  "Blog Post 3"
date:   2020-08-16 15:36:27
categories: blog assignment
permalink: posts/blog-post-3
author: Phil Chodrow
---


Rampant misinformation---often called "fake news"---is one of the defining features of contemporary democratic life. 

<figure class="image" style="width:50%">
    <img src="{{ site.baseurl }}_images/fake.png" alt="An alien man brandishing a data stick and screaming It's a FAAAAKE!">
    <figcaption><i>Senator Vreenak of the Romulan Federation finding out that the article he read about Jewish Space Lasers wasn't completely accurate.</i></figcaption>
</figure>

In this Blog Post, you will develop and assess a fake news classifier using Tensorflow. 

***Note***: *Working on this Blog Post in Google Colab is highly recommended.*


## Data Source 

Our data for this assignment comes from the article

- Ahmed H, Traore I, Saad S. (2017) “Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques. In: Traore I., Woungang I., Awad A. (eds) *Intelligent, Secure, and Dependable Systems in Distributed and Cloud Environments*. ISDDC 2017. *Lecture Notes in Computer Science*, vol 10618. Springer, Cham (pp. 127-138).

I accessed it [from Kaggle](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset). I have done a small amount of data cleaning for you already, and performed a train-test split. 


## §0. Writing Expectations

This is another "tutorial format" blog post, which means that, after you write your code, you should craft writing aiming to explain your steps to someone who is less familiar with machine learning and TensorFlow. When reviewing your submission, ask yourself: 

> Three weeks ago, could I have learned how to analyze text data by reading this blog post? 

If yes, you are good to go! If not, please take some additional time to write something that others could learn from. 

## §1. Acquire Training Data 

I have hosted a training data set at the below URL. You can either read it into Python directly (via `pd.read_csv()`) or download it to your computer and read it from disk. 

```python
train_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_train.csv?raw=true"
```

Each row of the data corresponds to an article. The `title` column gives the title of the article, while the `text` column gives the full article text. The final column, called `fake`, is `0` if the article is true and `1` if the article contains fake news, as determined by the authors of the paper above. 


## §2. Make a Dataset

Write a function called `make_dataset`. This function should do two things: 

1. *Remove stopwords* from the article `text` and `title`. A stopword is a word that is usually considered to be uninformative, such as "the," "and," or "but." You may find [this StackOverFlow thread](https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe) to be helpful. 
2. Construct and return a `tf.data.Dataset` with two inputs and one output. The input should be of the form `(title, text)`, and the output should consist only of the `fake` column. You may find it helpful to consult [these lecture notes](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16B/blob/master/lectures/tf/tf-4.ipynb) or [this tutorial](https://www.tensorflow.org/guide/-keras/functional) for reference on how to construct and use `Dataset`s with multiple inputs. 

Call the function `make_dataset` on your training dataframe to produce a `Dataset`. You may wish to `batch` your `Dataset` prior to returning it, which can be done like this: `my_data_set.batch(100)`. Batching causes your model to train on chunks of data rather than individual rows. This can sometimes reduce accuracy, but can also greatly increase the speed of training. Finding a balance is key. I found batches of 100 rows to work well. 

### Validation Data

After you've constructed your primary `Dataset`, split of 20% of it to use for validation. 

## §3. Create Models 

Please use machine learning to offer a perspective on the following question: 

> When detecting fake news, is it most effective to focus on only the title of the article, the full text of the article, or both? 

To address this question, create **three (3)** TensorFlow models. 

1. In the first model, you should use **only the article title** as an input. 
2. In the second model, you should use **only the article text** as an input. 
3. In the third model, you should use **both the article title and the article text** as input. 

Train your models on the training data until they appear to be "fully" trained. Assess and compare their performance. 

### Notes

- For the first two models, you don't have to create new `Dataset`s. Instead, just specify the `inputs` to the `keras.Model` appropriately, and TensorFlow will automatically ignore the unused inputs in the `Dataset`. 
- The lecture notes and tutorials linked above are likely to be helpful as you are creating your models as well. 
- **You will need to use the Functional API, rather than the Sequential API, for this modeling task.** 
- When using the Functional API, it is possible to use the same layer in multiple parts of your model; see [this tutorial](https://www.tensorflow.org/guide/keras/functional) for examples. I recommended that you share an embedding layer for both the article `title` and `text` inputs. 
- **You may encounter overfitting**, in which case `Dropout` layers can help. 

You're free to be creative when designing your models. If you're feeling very stuck, start with some of the pipelines for processing text that we've seen in lecture, and iterate from there. 

### What Accuracy Should You Aim For? 

Your three different models might have noticeably different performance. **Your best model should be able to score at least 95% validation accuracy**. If you can reach a consistent validation performance of 97% or more, that's a very good result. 

After comparing the performance of each model on validation data, make a recommendation regarding the question at the beginning of this section. Should algorithms use the title, the text, or both when seeking to detect fake news? 

## §4. Model Evaluation

Now we'll test your model performance on unseen test data. For this part, you can focus on your **best** model, and ignore the other two. 

Once you're satisfied with your best model's performance on validation data, download the test data here:  

```python
test_url = "https://github.com/PhilChodrow/PIC16b/blob/master/datasets/fake_news_test.csv?raw=true"
```

You'll need to convert this data using the `make_dataset` function you defined in Part §2. Then, evaluate your model on the data. If we used your model as a fake news detector, how often would we be right? 

## §5. Embedding Visualization

Visualize and comment on the *embedding* that your model learned (you did use an embedding, right?). Are you able to find any interesting patterns or associations in the words that the model found useful when distinguishing real news from fake news?  

I'd suggest that you create an embedding in a relatively large number of dimensions (say, 10) and then use PCA to reduce the dimension down to a visualizable number. This procedure was demonstrated [in lecture](https://nbviewer.jupyter.org/github/PhilChodrow/PIC16B/blob/master/lectures/tf/tf-3.ipynb). 


## §6. Tidy Up

1. Take some time to ensure that your code is as concise as possible. Have you taken full advantage of functions to minimize code duplication? 
2. Take some time to ensure that your explanations of each of your code steps are clear and helpful for an untrained reader. 
3. Submit a link to your post on CCLE! 
